{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import socket\n",
    "\n",
    "output_path = os.path.join('..', 'data', 'transcripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexps = [\n",
    "    (re.compile('♪[^♪]*♪|\\[[^\\]]*\\]|\\([^\\)]*\\)'), ' '),\n",
    "    (re.compile('<\\/?[\\w ]*>'), ' '), # for <\\br> and similar tags\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_to_skip = [\n",
    "    'https://scrapsfromtheloft.com/2019/10/27/jerry-seinfeld-playboy-interview-1993/',\n",
    "    'https://scrapsfromtheloft.com/2019/10/15/bill-cosby-playboy-interview-1985/',\n",
    "    'https://scrapsfromtheloft.com/2019/07/06/katherine-ryan-in-trouble-transcript/', # link to other site\n",
    "    'https://scrapsfromtheloft.com/2019/07/05/katherine-ryan-glitter-room-transcript/', # Unable to connect\n",
    "    'https://scrapsfromtheloft.com/2019/04/01/in-conversation-with-jerry-seinfeld/',\n",
    "    'https://scrapsfromtheloft.com/2018/10/30/lenny-bruce-unspruced-review-judith-crist/',\n",
    "    'https://scrapsfromtheloft.com/2018/10/03/richard-pryor-live-in-concert-review-carl-bennett-cinemonkey/',\n",
    "    'https://scrapsfromtheloft.com/2018/01/05/dave-chappelle-equanimity-2017-transcripcion-completa/',\n",
    "    'https://scrapsfromtheloft.com/2018/01/05/dave-chappelle-hbo-half-hour-1998-traduzione-italiana/',\n",
    "    'https://scrapsfromtheloft.com/2017/10/18/louis-c-k-the-rolling-stone-interview-2013/',\n",
    "    'https://scrapsfromtheloft.com/2017/10/02/jim-jefferies-e-il-controllo-della-armi-in-america/',\n",
    "    'https://scrapsfromtheloft.com/2017/08/23/doug-stanhope-no-refunds-2007-trascrizione-italiana/',\n",
    "    'https://scrapsfromtheloft.com/2017/04/21/larry-king-interview-robin-williams-2007/',\n",
    "    'https://scrapsfromtheloft.com/2017/04/12/george-carlin-jamming-new-york-testo-italiano-completo/',\n",
    "    'https://scrapsfromtheloft.com/2017/04/12/george-carlin-diseased-1999-testo-italiano-completo/',\n",
    "    'https://scrapsfromtheloft.com/2017/04/12/george-carlin-bad-2008-testo-italiano-completo/',\n",
    "    'https://scrapsfromtheloft.com/2017/01/11/robin-williams-playboy-interview-1992/',\n",
    "    'https://scrapsfromtheloft.com/2016/11/09/playboy-interview-george-carlin/',\n",
    "]\n",
    "ok_pages = [\n",
    "    'https://scrapsfromtheloft.com/2020/01/13/dave-chappelle-acceptance-speech-2019-mark-twain-prize/',\n",
    "    'https://scrapsfromtheloft.com/2020/01/07/ricky-gervais-2020-golden-globes-monologue-transcript/',\n",
    "    'https://scrapsfromtheloft.com/2019/10/20/real-time-with-bill-maher-new-rule-prickstarter/',\n",
    "    'https://scrapsfromtheloft.com/2019/09/11/new-rule-the-fudge-report-real-time-with-bill-maher/',\n",
    "    'https://scrapsfromtheloft.com/2019/05/18/doug-stanhope-babies-and-abortion/',\n",
    "    'https://scrapsfromtheloft.com/2019/03/18/ricky-gervais-2011-golden-globes-opening-monologue/',\n",
    "    'https://scrapsfromtheloft.com/2019/03/18/ricky-gervais-2016-golden-globes-opening-monologue/',\n",
    "    'https://scrapsfromtheloft.com/2019/02/18/politically-correct-language-george-carlin/',\n",
    "    'https://scrapsfromtheloft.com/2018/08/11/dick-gregory-speech-st-johns-baptist-church-may-20-1963/',\n",
    "    'https://scrapsfromtheloft.com/2018/05/23/trevor-noah-royal-wedding-2018/',\n",
    "    'https://scrapsfromtheloft.com/2018/05/16/doug-stanhope-on-nationalism/',\n",
    "    'https://scrapsfromtheloft.com/2018/03/27/ricky-gervais-2012-golden-globes-opening-monologue/',\n",
    "    'https://scrapsfromtheloft.com/2017/10/25/george-carlin-pro-life-abortion-and-the-sanctity-of-life/',\n",
    "    'https://scrapsfromtheloft.com/2017/10/25/richard-pryors-monologue-saturday-night-live-1975/',\n",
    "    'https://scrapsfromtheloft.com/2017/10/06/the-daily-show-fox-news-las-vegas-shooting-2017/',\n",
    "    'https://scrapsfromtheloft.com/2017/10/03/george-carlin-religion-is-bullshit/',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673ecaa8ed484a79b1d0962f361a5b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processed another  10 blocks, for a total of 10\n",
      "[INFO] Processed another  10 blocks, for a total of 20\n",
      "[INFO] Processed another  10 blocks, for a total of 30\n",
      "[INFO] Processed another  10 blocks, for a total of 40\n",
      "[INFO] Processed another  10 blocks, for a total of 50\n",
      "[INFO] Processed another  10 blocks, for a total of 60\n",
      "[INFO] Processed another  10 blocks, for a total of 70\n",
      "[INFO] Processed another  10 blocks, for a total of 80\n",
      "[INFO] Processed another  10 blocks, for a total of 90\n",
      "[INFO] Processed another  10 blocks, for a total of 100\n",
      "[INFO] Processed another  10 blocks, for a total of 110\n",
      "[INFO] Processed another  10 blocks, for a total of 120\n",
      "[INFO] Processed another  10 blocks, for a total of 130\n",
      "[INFO] Processed another  10 blocks, for a total of 140\n",
      "[INFO] Processed another  10 blocks, for a total of 150\n",
      "[INFO] Processed another  10 blocks, for a total of 160\n",
      "[INFO] Processed another  10 blocks, for a total of 170\n",
      "[INFO] Processed another  10 blocks, for a total of 180\n",
      "[INFO] Processed another  10 blocks, for a total of 190\n",
      "[INFO] Processed another  10 blocks, for a total of 200\n",
      "[INFO] Processed another  10 blocks, for a total of 210\n",
      "[INFO] Processed another  10 blocks, for a total of 220\n",
      "[INFO] Processed another  10 blocks, for a total of 230\n",
      "[INFO] Processed another  10 blocks, for a total of 240\n",
      "[INFO] Processed another  10 blocks, for a total of 250\n",
      "[INFO] Processed another  10 blocks, for a total of 260\n",
      "[INFO] Processed another  10 blocks, for a total of 270\n",
      "[INFO] Processed another  10 blocks, for a total of 280\n",
      "[INFO] Processed another  10 blocks, for a total of 290\n",
      "[INFO] Processed another  10 blocks, for a total of 300\n",
      "[INFO] Processed another  10 blocks, for a total of 310\n",
      "[INFO] Processed another  10 blocks, for a total of 320\n",
      "[INFO] Processed another  10 blocks, for a total of 330\n",
      "[INFO] Processed another  10 blocks, for a total of 340\n",
      "[INFO] Processed another  10 blocks, for a total of 350\n",
      "[INFO] Processed another  7 blocks, for a total of 357\n",
      "[INFO] Processed another  0 blocks, for a total of 357\n",
      "[INFO] Processed another  0 blocks, for a total of 357\n",
      "[INFO] Processed another  0 blocks, for a total of 357\n",
      "[INFO] Processed another  0 blocks, for a total of 357\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://scrapsfromtheloft.com/comedy/page/{}/'\n",
    "\n",
    "def save_file(path, txt, encoding=None):\n",
    "    # Create the corresponding folder (if needed)\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w', encoding=encoding) as out_file:\n",
    "        out_file.writelines(txt)\n",
    "\n",
    "\n",
    "def process_block(block):\n",
    "    result = []\n",
    "    # If not text, skip\n",
    "    try:\n",
    "        if block.name in ['img'] or (block.name == 'div' and block.get('class', [''])[0] == 'yarpp-related'):\n",
    "            return result\n",
    "    except AttributeError:\n",
    "        print('[ERROR] AttributeError!')\n",
    "        print(type(block))\n",
    "        print(block)\n",
    "        print('---------------------------------')\n",
    "    # If is a tag, process it's content\n",
    "    if isinstance(block, Tag):\n",
    "        for sub_block in block.contents:\n",
    "            result.extend(process_block(sub_block))\n",
    "        return result\n",
    "    for regexp, sub_str in regexps:\n",
    "        block = regexp.sub(sub_str, block)\n",
    "    block = block.strip()\n",
    "    if block:\n",
    "        result.append(block)\n",
    "    return result\n",
    "\n",
    "\n",
    "def scrap_transcript(url, file_path):\n",
    "    try:\n",
    "        transcript_page = requests.get(url)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print('[ERROR] Connection error to', url)\n",
    "        return\n",
    "    transcript_soup = BeautifulSoup(transcript_page.content, 'html.parser')\n",
    "    content_blocks = transcript_soup.findAll('div', 'post-content')\n",
    "    if len(content_blocks) != 1:\n",
    "        print('[WARN] strange content in', url)\n",
    "        return\n",
    "    content = process_block(content_blocks[0])\n",
    "    stripped_content = ['']\n",
    "    for line in content:\n",
    "        if len(stripped_content[-1]) < 200:\n",
    "            stripped_content[-1] += ' ' + line\n",
    "        else:\n",
    "            stripped_content.append(line)\n",
    "    save_file(file_path, '\\n'.join(stripped_content), encoding='utf8')\n",
    "\n",
    "\n",
    "n_batches = 40\n",
    "skip_downloaded = False\n",
    "n_processed = 0\n",
    "pbar = tqdm(total=n_batches)\n",
    "for i in range(n_batches):\n",
    "    pbar.set_description('Loading {} batch...'.format(i+1))\n",
    "#     time.sleep(1)\n",
    "    page = requests.get(URL.format(i))\n",
    "    pbar.set_description('Processing {} batch...'.format(i+1))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    blocks = soup.body.findAll('div', 'fusion-post-content post-content')\n",
    "    for j, block in enumerate(blocks):\n",
    "        pbar.set_description('Processing {} block...'.format(j+1))\n",
    "        block_title = block.find('h2', 'entry-title fusion-post-title').a\n",
    "        transcript_url = block_title['href']\n",
    "        file_name = transcript_url[:-1].rsplit('/', 1)[-1]\n",
    "        file_path = os.path.join(output_path, file_name + '.txt')\n",
    "        # Skip `bad` pages\n",
    "        if transcript_url in pages_to_skip:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "            continue\n",
    "        if not ('transcript' in block_title.contents[0].lower() or transcript_url in ok_pages):\n",
    "            print('[WARN] Possibly page without transcript!', transcript_url)\n",
    "        if not (os.path.exists(file_path) and skip_downloaded):\n",
    "            try:\n",
    "                scrap_transcript(transcript_url, file_path)\n",
    "            except Exception:\n",
    "                print('[ERROR] Some error on:', transcript_url)\n",
    "    n_processed += len(blocks)\n",
    "    print('[INFO] Processed another ', len(blocks), 'blocks, for a total of', n_processed)\n",
    "    pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
